import requests
from fake_useragent import UserAgent
import xml.etree.ElementTree as ET
import json
import time
import uuid
import asyncio
import httpx
import re
from schema import DbDTO, AgentData
from datetime import date, datetime
from typing import Optional

sitemaps = [
    'https://property.jll.com/sitemap-properties.xml',
]


HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:146.0) Gecko/20100101 Firefox/146.0",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Referer": "https://property.jll.com/search?tenureTypes=rent&propertyTypes=office&orderBy=asc&sortBy=rentPrice",
    "Sec-GPC": "1",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "same-origin",
    "Sec-Fetch-User": "?1",
    "If-None-Match": '"6uhwaqwe2q6get"',
    "Priority": "u=0, i",
}


def extract_next_data(html: str) -> dict | None:
    marker = '<script id="__NEXT_DATA__" type="application/json">'
    start = html.find(marker)
    if start == -1:
        return None

    start += len(marker)
    end = html.find("</script>", start)
    if end == -1:
        return None

    raw = html[start:end].strip()
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        return None


def extract_listing_from_html(html: str) -> dict | None:
    data = extract_next_data(html)
    if not data:
        return None
    try:
        return data["props"]["pageProps"]
    except (KeyError, TypeError):
        return None


def convert_jll_to_dto(page_props: dict, url: str) -> DbDTO | None:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JLL pageProps –≤ DbDTO –æ–±—ä–µ–∫—Ç
    """
    try:
        property_data = page_props.get("property", {})
        if not property_data:
            return None
        
        # –ë–∞–∑–æ–≤—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        listing_id = str(property_data.get("id", "") or property_data.get("refId", ""))
        if not listing_id:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –∫–∞–∫ fallback
            listing_id = url.split("/")[-1] if "/" in url else "unknown"
        
        # –ê–¥—Ä–µ—Å
        address_parts = []
        if property_data.get("address"):
            address_parts.append(property_data["address"])
        if property_data.get("city"):
            address_parts.append(property_data["city"])
        if property_data.get("state"):
            address_parts.append(property_data["state"])
        if property_data.get("postcode"):
            address_parts.append(property_data["postcode"])
        address = ", ".join(address_parts) if address_parts else "Address not found"
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        coordinates = None
        if property_data.get("latitude") and property_data.get("longitude"):
            coordinates = f"{property_data['latitude']},{property_data['longitude']}"
        
        # –¢–∏–ø –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        listing_type = None
        tenure_types = property_data.get("tenureTypes", [])
        if "rent" in tenure_types and "sale" in tenure_types:
            listing_type = "For Sale / For Lease"
        elif "rent" in tenure_types:
            listing_type = "For Lease"
        elif "sale" in tenure_types:
            listing_type = "For Sale"
        
        # –°—Ç–∞—Ç—É—Å
        listing_status = None
        labels = property_data.get("labels", [])
        if labels:
            listing_status = ", ".join(labels)
        
        # –¶–µ–Ω—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        sale_price = property_data.get("salePrice")
        lease_price = property_data.get("rentPrice")
        
        # –ï—Å–ª–∏ —Ü–µ–Ω–∞ - –æ–±—ä–µ–∫—Ç, —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –µ—ë
        if isinstance(sale_price, dict):
            # –ú–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª—è–º–∏ amount, currency, unit
            amount = sale_price.get("amount")
            currency = sale_price.get("currency", "USD")
            unit = sale_price.get("unit", "")
            
            if amount is not None:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ü–µ–Ω—É
                if unit:
                    sale_price = f"{currency} {amount}/{unit}"
                else:
                    sale_price = f"{currency} {amount}"
            else:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ª—è
                sale_price = sale_price.get("formatted") or sale_price.get("value") or sale_price.get("display")
                if sale_price and not isinstance(sale_price, str):
                    sale_price = str(sale_price)
        
        if isinstance(lease_price, dict):
            amount = lease_price.get("amount")
            currency = lease_price.get("currency", "USD")
            unit = lease_price.get("unit", "")
            
            if amount is not None:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ü–µ–Ω—É –∞—Ä–µ–Ω–¥—ã
                if unit:
                    lease_price = f"{currency} {amount}/{unit}"
                else:
                    lease_price = f"{currency} {amount}"
            else:
                lease_price = lease_price.get("formatted") or lease_price.get("value") or lease_price.get("display")
                if lease_price and not isinstance(lease_price, str):
                    lease_price = str(lease_price)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —ç—Ç–æ —á–∏—Å–ª–æ
        if sale_price and not isinstance(sale_price, str):
            sale_price = str(sale_price)
        if lease_price and not isinstance(lease_price, str):
            lease_price = str(lease_price)
        
        # –ü–ª–æ—â–∞–¥—å
        size_str = None
        surface_area = property_data.get("surfaceArea", {})
        if surface_area and "value" in surface_area:
            value = surface_area["value"]
            unit = surface_area.get("unit", "feet")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø value - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º –∏–ª–∏ —á–∏—Å–ª–æ–º
            if isinstance(value, dict):
                if "min" in value and "max" in value:
                    if value["min"] == value["max"]:
                        size_str = f"{value['min']:,} {unit}"
                    else:
                        size_str = f"{value['min']:,}-{value['max']:,} {unit}"
                elif "min" in value:
                    size_str = f"{value['min']:,}+ {unit}"
            elif isinstance(value, (int, float)):
                # –ï—Å–ª–∏ value - –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
                size_str = f"{int(value):,} {unit}"
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        description = None
        description_sections = property_data.get("descriptionSections", [])
        if description_sections:
            descriptions = []
            for section in description_sections:
                if section.get("content"):
                    descriptions.append(section["content"])
            if descriptions:
                description = " ".join(descriptions)
                # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏ (–ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)
                import re
                description = re.sub(r'<[^>]+>', '', description)
        
        # Highlights
        highlights_list = None
        highlights = property_data.get("highlights", [])
        if highlights:
            highlights_list = [h.get("title", "") for h in highlights if h.get("title")]
        
        # –§–æ—Ç–æ
        photos_list = property_data.get("images", [])
        
        # Brochure PDF - –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ property_data –∏ –≤ –∫–æ—Ä–Ω–µ page_props
        brochure_pdf = None
        brochures = property_data.get("brochures", [])
        if not brochures:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –∫–æ—Ä–Ω–µ page_props
            brochures = page_props.get("brochures", [])
        
        if brochures:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π PDF
            for brochure in brochures:
                if isinstance(brochure, str) and brochure.lower().endswith('.pdf'):
                    brochure_pdf = brochure
                    break
        
        # –ï—Å–ª–∏ brochure –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å
        if not brochure_pdf:
            brochure_pdf = url.rstrip('/') + '/brochure'
        
        # Virtual tour
        virtual_tour = None
        virtual_tours = property_data.get("virtualTours", [])
        if virtual_tours:
            virtual_tour = virtual_tours[0] if isinstance(virtual_tours[0], str) else None
        
        # –ê–≥–µ–Ω—Ç—ã
        agents_list = []
        brokers = property_data.get("brokers", [])
        if not brokers:
            # –ü—Ä–æ–±—É–µ–º –∏–∑ –∫–æ—Ä–Ω—è page_props
            brokers = page_props.get("brokers", [])
        
        for broker in brokers:
            email = broker.get("email")
            if not email or email.strip() == "":
                email = None
            
            # –ü–æ–ª—É—á–∞–µ–º –ª–∏—Ü–µ–Ω–∑–∏—é –∏–∑ brokerLicenses
            license_num = None
            broker_licenses = broker.get("brokerLicenses", [])
            if broker_licenses and len(broker_licenses) > 0:
                license_num = broker_licenses[0].get("licenseNumber")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ñ–∏—Å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ entityLicenses
            office_name = None
            office_phone = None
            entity_licenses = broker.get("entityLicenses", [])
            if entity_licenses and len(entity_licenses) > 0:
                office_name = entity_licenses[0].get("company")
                office_phone = entity_licenses[0].get("mainOfficePhone")
            
            agent = AgentData(
                name=broker.get("name"),
                title=broker.get("jobTitle"),
                license=license_num,
                phone_primary=broker.get("telephone"),
                email=email,
                photo_url=broker.get("photo"),
                office_name=office_name,
                office_phone=office_phone,
                social_media=broker.get("linkedin"),
            )
            agents_list.append(agent)
        
        # Property type
        property_type = property_data.get("propertyType")
        property_types = property_data.get("propertyTypes", [])
        if property_types and not property_type:
            property_type = property_types[0]
        
        # Building class
        building_class = property_data.get("buildingClass")
        
        # Year built (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö)
        year_built = None
        
        # Listing details - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É property –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
        listing_details_dict = property_data.copy()
        # –£–¥–∞–ª—è–µ–º –±–æ–ª—å—à–∏–µ –º–∞—Å—Å–∏–≤—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        for key in ["brokers", "images", "brochures", "highlights", "descriptionSections"]:
            listing_details_dict.pop(key, None)
        
        # –°–æ–∑–¥–∞–µ–º DbDTO
        dto = DbDTO(
            source_name="jll",
            listing_id=listing_id,
            listing_link=url,
            listing_type=listing_type,
            listing_status=listing_status,
            address=address,
            coordinates=coordinates,
            building_number=None,  # –ú–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ address
            street_name=property_data.get("address"),
            city=property_data.get("city"),
            state=property_data.get("state"),
            zipcode=property_data.get("postcode"),
            sale_price=str(sale_price) if sale_price else None,
            lease_price=str(lease_price) if lease_price else None,
            size=size_str,
            property_name=property_data.get("title"),
            property_type=property_type,
            building_class=building_class,
            property_description=description,
            property_highlights="; ".join(highlights_list) if highlights_list else None,
            location_highlights=highlights_list,
            listing_details=listing_details_dict if listing_details_dict else None,
            photos=photos_list if photos_list else None,
            brochure_pdf=brochure_pdf,
            virtual_tour=virtual_tour,
            agents=agents_list if agents_list else None,
            year_built=year_built,
        )
        
        return dto
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ DbDTO: {e}")
        import traceback
        traceback.print_exc()
        return None


def fetch_jll_listing(url: str) -> DbDTO | None:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–∞ JLL –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ DbDTO
    """
    resp = requests.get(url, headers=HEADERS, timeout=30)
    resp.raise_for_status()
    page_props = extract_listing_from_html(resp.text)
    if not page_props:
        return None
    return convert_jll_to_dto(page_props, url)


def parse_sitemap(sitemap_url: str) -> list[str]:
    """
    –ü–∞—Ä—Å–∏—Ç sitemap XML –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∏–∑ <loc> —Ç–µ–≥–æ–≤
    """
    try:
        response = requests.get(sitemap_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        
        root = ET.fromstring(response.content)
        
        # Namespace –¥–ª—è sitemap
        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ URL
        urls = []
        for url_elem in root.findall('.//ns:url', namespace):
            loc_elem = url_elem.find('ns:loc', namespace)
            if loc_elem is not None and loc_elem.text:
                urls.append(loc_elem.text.strip())
        
        return urls
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ sitemap {sitemap_url}: {e}")
        return []


async def parse_listing_async(client: httpx.AsyncClient, url: str, semaphore: asyncio.Semaphore) -> tuple[DbDTO | None, str | None]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç –æ–¥–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–æ URL
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (dto, error_message)
    """
    async with semaphore:
        try:
            response = await client.get(url, headers=HEADERS, timeout=30.0, follow_redirects=True)
            response.raise_for_status()
            
            page_props = extract_listing_from_html(response.text)
            if not page_props:
                error_msg = f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å __NEXT_DATA__ –∏–∑ {url}"
                print(error_msg)
                return None, error_msg
            
            dto = convert_jll_to_dto(page_props, url)
            if dto:
                return dto, None
            else:
                error_msg = f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ DbDTO –∏–∑ {url}"
                print(error_msg)
                return None, error_msg
                
        except httpx.HTTPStatusError as e:
            error_msg = f"‚ùå HTTP –æ—à–∏–±–∫–∞ {e.response.status_code} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}"
            print(error_msg)
            return None, error_msg
        except httpx.TimeoutException:
            error_msg = f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}"
            print(error_msg)
            return None, error_msg
        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {url}: {e}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return None, error_msg


async def parse_listings_async(listing_urls: list[str], concurrency: int = 10, limit: int = None) -> list[DbDTO]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    
    Args:
        listing_urls: –°–ø–∏—Å–æ–∫ URL –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        concurrency: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–∞)
    
    Returns:
        list: –°–ø–∏—Å–æ–∫ DbDTO –æ–±—ä–µ–∫—Ç–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    """
    if limit:
        listing_urls = listing_urls[:limit]
        print(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ {limit} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    semaphore = asyncio.Semaphore(concurrency)
    
    async with httpx.AsyncClient() as client:
        tasks = [parse_listing_async(client, url, semaphore) for url in listing_urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏
    parsed_listings = []
    errors = []
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            error_msg = f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è {i+1} ({listing_urls[i]}): {result}"
            print(error_msg)
            errors.append(error_msg)
        elif isinstance(result, tuple):
            dto, error_msg = result
            if dto:
                parsed_listings.append(dto)
                print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ {len(parsed_listings)}/{len(listing_urls)}: {dto.listing_link}")
            elif error_msg:
                errors.append(f"{i+1}. {error_msg}")
        else:
            error_msg = f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è {i+1}: {type(result)}"
            print(error_msg)
            errors.append(error_msg)
    
    print(f"\n{'='*60}")
    print(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(parsed_listings)} –∏–∑ {len(listing_urls)}")
    if errors:
        print(f"\n–û—à–∏–±–∫–∏ ({len(errors)}):")
        for error in errors:
            print(f"  {error}")
    print(f"{'='*60}")
    
    return parsed_listings


def parse_listings(listing_urls: list[str], concurrency: int = 10, limit: int = None) -> list[DbDTO]:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    """
    return asyncio.run(parse_listings_async(listing_urls, concurrency, limit))


if __name__ == "__main__":
    # –®–∞–≥ 1: –ü–∞—Ä—Å–∏–º sitemap –∏ —Å–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏
    print("=" * 60)
    print("–®–ê–ì 1: –ü–∞—Ä—Å–∏–Ω–≥ sitemap –∏ —Å–±–æ—Ä —Å—Å—ã–ª–æ–∫")
    print("=" * 60)
    
    all_urls = []
    for sitemap_url in sitemaps:
        print(f"–ü–∞—Ä—Å–∏–º sitemap: {sitemap_url}")
        urls = parse_sitemap(sitemap_url)
        all_urls.extend(urls)
        print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(urls)}")
    
    print(f"\n–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —Å—Å—ã–ª–æ–∫: {len(all_urls)}")
    
    # –®–∞–≥ 2: –ü–∞—Ä—Å–∏–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10)
    print("\n" + "=" * 60)
    print("–®–ê–ì 2: –ü–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    print("=" * 60)
    TEST_LIMIT = 10  # –î–ª—è —Ç–µ—Å—Ç–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    listings_data = parse_listings(all_urls, concurrency=10, limit=TEST_LIMIT)
    
    # –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
    print("\n" + "=" * 60)
    print("–®–ê–ì 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("=" * 60)
    output_file = 'listings_data.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DbDTO –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è JSON
        listings_dict = [dto.model_dump(exclude_none=True) for dto in listings_data]
        json.dump(listings_dict, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\n‚úì –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª '{output_file}'")
    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(listings_data)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—è–º
    if listings_data:
        print(f"\n{'='*60}")
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ü–û–õ–Ø–ú")
        print(f"{'='*60}")
        
        total = len(listings_data)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è
        with_address = sum(1 for dto in listings_data if dto.address and dto.address != "Address not found")
        with_coordinates = sum(1 for dto in listings_data if dto.coordinates)
        with_listing_type = sum(1 for dto in listings_data if dto.listing_type)
        with_listing_status = sum(1 for dto in listings_data if dto.listing_status)
        
        # –¶–µ–Ω—ã
        with_sale_price = sum(1 for dto in listings_data if dto.sale_price)
        with_lease_price = sum(1 for dto in listings_data if dto.lease_price)
        with_any_price = sum(1 for dto in listings_data if dto.sale_price or dto.lease_price)
        
        # –ü–ª–æ—â–∞–¥—å –∏ —Ç–∏–ø
        with_size = sum(1 for dto in listings_data if dto.size)
        with_property_type = sum(1 for dto in listings_data if dto.property_type)
        with_building_class = sum(1 for dto in listings_data if dto.building_class)
        
        # –û–ø–∏—Å–∞–Ω–∏–µ –∏ highlights
        with_description = sum(1 for dto in listings_data if dto.property_description)
        with_highlights = sum(1 for dto in listings_data if dto.location_highlights and len(dto.location_highlights) > 0)
        
        # –ú–µ–¥–∏–∞
        with_photos = sum(1 for dto in listings_data if dto.photos and len(dto.photos) > 0)
        with_brochure = sum(1 for dto in listings_data if dto.brochure_pdf)
        with_virtual_tour = sum(1 for dto in listings_data if dto.virtual_tour)
        
        # –ê–≥–µ–Ω—Ç—ã
        with_agents = sum(1 for dto in listings_data if dto.agents and len(dto.agents) > 0)
        
        # Listing details
        with_listing_details = sum(1 for dto in listings_data if dto.listing_details)
        
        def print_stat(label, count, total_count):
            percentage = (count / total_count * 100) if total_count > 0 else 0
            print(f"  {label:30} {count:4}/{total_count:4} ({percentage:5.1f}%)")
        
        print("\nüìã –ë–∞–∑–æ–≤—ã–µ –ø–æ–ª—è:")
        print_stat("–ê–¥—Ä–µ—Å", with_address, total)
        print_stat("–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã", with_coordinates, total)
        print_stat("–¢–∏–ø –æ–±—ä—è–≤–ª–µ–Ω–∏—è", with_listing_type, total)
        print_stat("–°—Ç–∞—Ç—É—Å", with_listing_status, total)
        
        print("\nüí∞ –¶–µ–Ω—ã:")
        print_stat("–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏", with_sale_price, total)
        print_stat("–¶–µ–Ω–∞ –∞—Ä–µ–Ω–¥—ã", with_lease_price, total)
        print_stat("–õ—é–±–∞—è —Ü–µ–Ω–∞", with_any_price, total)
        
        print("\nüìê –ü–ª–æ—â–∞–¥—å –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
        print_stat("–ü–ª–æ—â–∞–¥—å", with_size, total)
        print_stat("–¢–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏", with_property_type, total)
        print_stat("–ö–ª–∞—Å—Å –∑–¥–∞–Ω–∏—è", with_building_class, total)
        
        print("\nüìù –û–ø–∏—Å–∞–Ω–∏–µ:")
        print_stat("–û–ø–∏—Å–∞–Ω–∏–µ", with_description, total)
        print_stat("Highlights", with_highlights, total)
        
        print("\nüñºÔ∏è  –ú–µ–¥–∏–∞:")
        print_stat("–§–æ—Ç–æ", with_photos, total)
        print_stat("Brochure PDF", with_brochure, total)
        print_stat("Virtual Tour", with_virtual_tour, total)
        
        print("\nüë• –ê–≥–µ–Ω—Ç—ã:")
        print_stat("–ê–≥–µ–Ω—Ç—ã", with_agents, total)
        
        print("\nüìÑ –î–µ—Ç–∞–ª–∏:")
        print_stat("Listing Details", with_listing_details, total)
        
        print(f"\n{'='*60}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        print(f"\n–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–≤–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è:")
        first_dict = listings_data[0].model_dump(exclude_none=True)
        print(json.dumps(first_dict, ensure_ascii=False, indent=2, default=str)[:500] + "...")